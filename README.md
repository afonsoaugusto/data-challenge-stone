# Data-Challenge-Stone - Data Platform

[![deepcode](https://www.deepcode.ai/api/gh/badge?key=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwbGF0Zm9ybTEiOiJnaCIsIm93bmVyMSI6ImFmb25zb2F1Z3VzdG8iLCJyZXBvMSI6ImRhdGEtY2hhbGxlbmdlLXN0b25lIiwiaW5jbHVkZUxpbnQiOmZhbHNlLCJhdXRob3JJZCI6MjMwNDAsImlhdCI6MTYxNzA1OTY3Nn0.yAAUnREvla7WJ8bzpoj_j_pZB7G6DY39r9llH7PSbHQ)](https://www.deepcode.ai/app/gh/afonsoaugusto/data-challenge-stone/_/dashboard?utm_content=gh%2Fafonsoaugusto%2Fdata-challenge-stone)
[![CircleCI](https://circleci.com/gh/afonsoaugusto/data-challenge-stone/tree/main.svg?style=svg)](https://circleci.com/gh/afonsoaugusto/data-challenge-stone/tree/main)

Desafio Data Challenge Stone na categoria Data Platform

- [Desafio](#desafio)
  * [DescriÃ§Ã£o](#descriÃ§Ã£o)
  * [Entrega 1](#entrega-1)
  * [Entrega 2](#entrega-2)
  * [Intens de avaliaÃ§Ã£o da soluÃ§Ã£o](#intens-de-avalia--o-da-soluÃ§Ã£o)
  * [Intens de avaliaÃ§Ã£o da apresentaÃ§Ã£o](#intens-de-avaliaÃ§Ã£o-da-apresentaÃ§Ã£o)
- [Arquitetura](#arquitetura)
  * [Airflow Operator](#Airflow-Operator)
  * [Spark Operator](#Spark-Operator)
  * [Spark Job](#Spark-Job)
  * [Airflow Operator](#Airflow-Operator)
  * [Minio Operator](#Minio-Operator)
- [Estrutura do Projeto](#estrutura-do-projeto)
  * [Devcontainer](#Devcontainers)
  * [Pipeline](#pipeline)
    + [Estrutura do diretÃ³rio spark-applications](#estrutura-do-diretÃ³rio-spark-applications)
- [SoluÃ§Ã£o](#soluÃ§Ã£o)
  * [Kubernetes](#kubernetes)
    + [Kind](#Kind)
    + [Helm](#Helm)
  * [Kubernetes-Operators](#kubernetes-operators)
    + [spark-on-k8s-operator](#spark-on-k8s-operator)
    + [Minio-operator](#Minio-operator)
    + [Airflow-operator](#Airflow-operator)
  * [Local setup](#local-setup)
    + [Variaveis de ambiente](#variaveis-de-ambiente)
    + [Executando Local setup](#executando-local-setup)
  * [Cleanup environment](#cleanup-environment)
- [ExecuÃ§Ã£o dos jobs](#execuÃ§Ã£o-dos-jobs)
  * [Pyspark-Operator](#pyspark-operator)
  * [Airflow-Operator](#airflow-operator)
    + [Acessando a console do airflow](#acessando-a-console-do-airflow)
    + [Executando o Workflow](#executando-o-workflow)
- [Deployando a soluÃ§Ã£o em um ambiente com o cluster jÃ¡ disponivel](#deployando-a-soluÃ§Ã£o-em-um-ambiente-com-o-cluster-jÃ¡-disponivel)
  * [Passo 0 - configurar as variaveis de ambiente](#passo-0---configurar-as-variaveis-de-ambiente)
  * [Passo 1 - configurar o acesso ao cluster](#passo-1---configurar-o-acesso-ao-cluster)
  * [Passo 2 - instalar os operadores no cluster](#passo-2---instalar-os-operadores-no-cluster)
  * [Passo 3 - EvoluÃ§Ã£o das aplicaÃ§Ãµes](#passo-3---evolu--o-das-aplica--es)
- [TODO](#todo)
- [ReferÃªncias](#referÃªncias)

## Desafio

### DescriÃ§Ã£o

Criar um cluster Spark no Kubernetes, e executar um job de spark com 3 [executors](https://spark.apache.org/docs/latest/cluster-overview.html#glossary).

Garanta de que cada nÃ³s do cluster de Kubernetes conversem entre si seguindo as boas prÃ¡ticas de seguranÃ§a:

* LimitaÃ§Ã£o de acesso a portas para a integraÃ§Ã£o
* CriaÃ§Ã£o de roles de usuÃ¡rios no cluster
  * Admin
  * Edit
  * View

O ambiente deve ser local e disponibilizado no github

### Entrega 1

Desenho da soluÃ§Ã£o + Imagens de Docker

### Entrega 2

ApresentaÃ§Ã£o do projeto em 20 min detalhando o problema e a soluÃ§Ã£o implementada

### Intens de avaliaÃ§Ã£o da soluÃ§Ã£o

* (p 1.5) Deployability (roteiro de implentaÃ§Ã£o)
* (p 1.5) Performance
* (p 1.5) Estrutura de cÃ³digos/artefatos (manutenibilidade)
* (p 2.0) RecuperaÃ§Ã£o em caso de falhas
* (p 2.0) DocumentaÃ§Ã£o
* (p 1.5) SeguranÃ§a

### Intens de avaliaÃ§Ã£o da apresentaÃ§Ã£o

* Conhecimento da soluÃ§Ã£o implementada
* Storytelling
* Maiores dificuldades
* Beneficios da soluÃ§Ã£o

## Arquitetura

O desenho da arquitetura estÃ¡ apresentado no relacionamento dos namespaces no k8s.

![k8s-namespaces](img/k8s-namespaces.png)

### Airflow Operator

![airflow-operator](img/namespaces/airflow-operator.png)

### Spark Operator

![spark-operator](img/namespaces/spark-operator.png)

### Spark Job

Namespace durante a execuÃ§Ã£o de uma SparkApplication com seus 3 executors que foram definidos no parametro *spec.executor.instances* do yaml de configuraÃ§Ã£o.

![spark-job](img/namespaces/spark-job.png)

### Minio Operator

![minio-operator](img/namespaces/minio-operator.png)

## Estrutura do Projeto

```sh
$tree -a -I .git -v
.
â”œâ”€â”€ .circleci  ------------------------------------------ DiretÃ³rio para o circleci                                           
â”‚   â””â”€â”€ config.yml  ------------------------------------- ConfiguraÃ§Ã£o da pipeline do circle ci
â”œâ”€â”€ .devcontainer  -------------------------------------- ConfiguraÃ§Ã£o para utilizar o devcontainer do vscode para desenvolvimento
â”‚   â”œâ”€â”€ Dockerfile  ------------------------------------- Dockerfile que serÃ¡ utilizado como terminal no vscode
â”‚   â”œâ”€â”€ devcontainer.json  ------------------------------ ConfiguraÃ§Ãµes do Devcontainer
â”‚   â””â”€â”€ library-scripts  -------------------------------- Scripts para auxiliar no setup ara rodar o Devcontainer docker-in-docker
â”‚       â”œâ”€â”€ common-debian.sh  --------------------------- Script para setup basico para debian like
â”‚       â””â”€â”€ docker-in-docker-debian.sh  ----------------- Script para configuraÃ§Ã£o do docker-in-docker
â”œâ”€â”€ .env.private  --------------------------------------- Arquivo de variaveis privadas, essas variaveis devem ficar no ambiente de CI ou um vault e serem setadas no ambiente. (excluido no .gitignore)
â”œâ”€â”€ .env.project  --------------------------------------- Arquivo de variaveis para customizar a execuÃ§Ã£o do projeto
â”œâ”€â”€ .gitignore  ----------------------------------------- .gitignore para nÃ£o subir para o repositÃ³rio arquivos nÃ£o necessÃ¡rios
â”œâ”€â”€ .kubectl_aliases  ----------------------------------- Carrega as variaveis dos arquivos .env e criar alguns alias para simplificar a utilizaÃ§Ã£o do Kubectl. alias k='kubectl'
â”œâ”€â”€ Case-Plataforma-de-Dados-Data-Platform.pdf  --------- DefiniÃ§Ãµes e regras para este projeto
â”œâ”€â”€ Makefile  ------------------------------------------- Makefile para automatizar os comandos mais recorrentes
â”œâ”€â”€ README.md  ------------------------------------------ README.md
â”œâ”€â”€ airflow-operator  ----------------------------------- DiretÃ³rio para as configuraÃ§Ãµes do airflow-operator
â”‚   â”œâ”€â”€ 01-airflow.sh  ---------------------------------- Script para setup do operador
â”‚   â”œâ”€â”€ airflow-namespace.yml  -------------------------- DefiniÃ§Ã£o do namespace utilizado pelo operador
â”‚   â”œâ”€â”€ airflow-rbac.yml  ------------------------------- DefiniÃ§Ã£o da role e rolebind para o airflow utilizar o spark-operator
â”‚   â””â”€â”€ dags  ------------------------------------------- DiretÃ³rio para conter as Dags (configuraÃ§Ã£o dos workflows) do airflow
â”‚       â”œâ”€â”€ spark-pagerank.yml  ------------------------- Exemplo de SparkApplication para a Dag spark_pagerank
â”‚       â”œâ”€â”€ spark-pi.yml  ------------------------------- Exemplo de SparkApplication para a Dag spark_pi
â”‚       â”œâ”€â”€ spark_pagerank.py  -------------------------- DefiniÃ§Ã£o da dag spark_pagerank
â”‚       â”œâ”€â”€ spark_pi.py  -------------------------------- DefiniÃ§Ã£o da dag spark_pi
â”‚       â””â”€â”€ test-data-pipeline.py  ---------------------- DefiniÃ§Ã£o da dag test-data-pipeline (esta dag nÃ£o utiliza o spark-operator)
â”œâ”€â”€ docker  --------------------------------------------- DiretÃ³rio para automatizar a criaÃ§Ã£o das imagens para a applications
â”‚   â”œâ”€â”€ Makefile  --------------------------------------- Makefile para automatizar os comandos *docker build* e *docker push*
â”‚   â”œâ”€â”€ build.sh  --------------------------------------- Script para automatizar a criaÃ§Ã£o dinamica das imagens
â”‚   â””â”€â”€ publish.sh  ------------------------------------- Script para automatizar a publicaÃ§Ã£o dinamica das imagens
â”œâ”€â”€ img  ------------------------------------------------ DiretÃ³rio de imagens do README
â”œâ”€â”€ kubernetes  ----------------------------------------- DiretÃ³rio para conter a automaÃ§Ã£o do kuberntes rodando local
â”‚   â”œâ”€â”€ auxiliaries-setup  ------------------------------ DiretÃ³rio para conter a automaÃ§Ã£o de ferramentas auxiliares. (No caso Ã© o minio uma interface para o S3 que poderia ser substituido pelo prorio S3)
â”‚   â”‚   â”œâ”€â”€ 01-minio.sh  -------------------------------- Script para instalaÃ§Ã£o do minio-operator via helm
â”‚   â”‚   â””â”€â”€ minio-namespace.yml  ------------------------ DefiniÃ§Ã£o do namespace para o minio-operator
â”‚   â””â”€â”€ local-setup ------------------------------------- DiretÃ³rio para conter a configuraÃ§Ã£o k8s local com kind 
â”‚       â”œâ”€â”€ kind-config.yml.tmpl  ----------------------- Template para configuraÃ§Ã£o do Kind - Ele vai receber de forma dinamica o nome do cluster a ser criado
â”‚       â””â”€â”€ scripts  ------------------------------------ Scripts auxiliares para iteraÃ§Ã£o com o cluster
â”‚           â”œâ”€â”€ 00-local-setup.sh  ---------------------- Script para realizar todo o setup
â”‚           â”œâ”€â”€ 01-install-kind.sh  --------------------- Script para instalar o kind
â”‚           â”œâ”€â”€ 02-install-kubectl.sh  ------------------ Script para instalar o kubectl
â”‚           â”œâ”€â”€ 03-install-helm.sh  --------------------- Script para instalar o helm
â”‚           â”œâ”€â”€ 04-install-mc-client.sh  ---------------- Script para instalar o client do minio
â”‚           â”œâ”€â”€ 99-cleanup.sh  -------------------------- Script para remover o cluster kind
â”‚           â””â”€â”€ 101-setup-dashboard.sh  ----------------- Script para instalar o dashboard do kubernetes. Como ele Ã© apenas para validar alguns estados do cluster de forma simplificada, ele ficou de fora do 00-local-setup.sh
â”œâ”€â”€ notas.txt  ------------------------------------------ Notas de observaÃ§Ãµes e scripts gerais para consulta rapida, este arquivo nÃ£o Ã© commitado. (excluido no .gitignore)
â”œâ”€â”€ spark-applications ---------------------------------- DiretÃ³rio para conter as aplicaÃ§Ãµes Spark
â”‚   â””â”€â”€ pagerank ---------------------------------------- AplicaÃ§Ã£o pagerank
â”‚       â”œâ”€â”€ Dockerfile ---------------------------------- Dockerfile para gerar a imagem da aplicaÃ§Ã£o
â”‚       â”œâ”€â”€ pagerank.py --------------------------------- Script pyspark da aplicaÃ§Ã£o
â”‚       â””â”€â”€ pagerank.yml -------------------------------- ConfiguraÃ§Ã£o da aplicaÃ§Ã£o
â””â”€â”€ spark-operator  ------------------------------------- DiretÃ³rio do spark-operator
    â”œâ”€â”€ install-spark-operator.sh  ---------------------- InstalaÃ§Ã£o do spark-operator com helm
    â””â”€â”€ spark-namespaces.yml  --------------------------- DefiniÃ§Ã£o dos namespaces para o spark-operator

14 directories, 41 files
```

### [Devcontainer](https://code.visualstudio.com/docs/remote/containers)

Este projeto contem uma definiÃ§Ã£o de devcontainer para execuÃ§Ã£o local. 
NÃ£o Ã© necessÃ¡rio utilizar a execuÃ§Ã£o em container ou no vscode. 
PorÃ©m se estiver utilizando vscode, o devcontainer simplifica para ter o mesmo ambiente rodando local em que o projeto foi desenvolvido.

O Devcontainer cria executa um container e monta o diretÃ³rio do projeto local no proprio container. 
Ele automatiza o mapeamento dos usuÃ¡rios da maquina com o container, portanto todo arquivo que for criado durante a execuÃ§Ã£o nÃ£o serÃ¡ com o root.

![devcontainer-architecture-containers](img/devcontainer-architecture-containers.png)

A estratÃ©gia utilizada foi a [docker-in-docker](https://itnext.io/docker-in-docker-521958d34efd), onde o container Ã© executado em modo privilegiado e o mesmo tem acesso a recursos do docker da maquina.

### Pipeline

Hoje a pipeline estÃ¡ fazendo somente o build das imagens das aplicaÃ§Ãµes no diretÃ³rio [spark-applications](./spark-applications)

#### Estrutura do diretÃ³rio spark-applications

* spark-applications
  * application-name
    * Dockerfile
    * application.py ou os arquivos necessaÅ•ios
    * application.yml (DefiniÃ§Ã£o da SparkApplication para referÃªncia)

```sh
â”œâ”€â”€ spark-applications
â”‚   â””â”€â”€ pagerank
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ pagerank.py
â”‚       â””â”€â”€ pagerank.yml
```

## SoluÃ§Ã£o

### Kubernetes

#### [Kind](https://kind.sigs.k8s.io/)

Foi escolhido o kind devido a possibilidade simular um cluster kubernetes com a possibilidade ser multi node para workers e termos HA para o control-plane.

Importante salientar que para ele operar Ã© necessÃ¡rio apenas o docker. O Kubectl se torna necessÃ¡rio para interagir com o cluster.

#### [Helm](https://helm.sh/docs/)

Foi escolhido utilizar o *helm* para deployar os *operators* para simplificar a sua gestÃ£o e criaÃ§Ã£o dos componentes necessÃ¡rios para a soluÃ§Ã£o.

### Kubernetes-Operators

#### [spark-on-k8s-operator](https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/)

O spark operator foi escolhido por ser uma simplificaÃ§Ã£o do setup do spark no kubernetes. 

No projeto temos a aplicaÃ§Ã£o *pagerank* declarada em dois locais:

```sh
â”œâ”€â”€ airflow-operator               ----- Para DeclaraÃ§Ã£o da Dag no Airflow -----
â”‚   â””â”€â”€ dags
â”‚       â”œâ”€â”€ spark-pagerank.yml
â”‚       â”œâ”€â”€ spark_pagerank.py
â”œâ”€â”€ spark-applications            ----- Para criar a imagem base e pode executar um SparkApplication diretamente -----
â”‚   â””â”€â”€ pagerank
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ pagerank.py
â”‚       â””â”€â”€ pagerank.yml
```

#### [Minio-operator](https://github.com/minio/operator/blob/master/README.md)

O minio operator foi escolhido por ser uma interface de abstraÃ§Ã£o para uma estrutura hdfs. 
Ele tambÃ©m cria um [pvc](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) local caso nÃ£o queira utilizar um s3 como storage.

Era intuito utilizar ele no projeto, porÃ©m nÃ£o teve tempo habil para utilza-lo corretamente.

#### [Airflow-operator](https://github.com/bitnami/charts/tree/master/bitnami/airflow)

O airflow operator da bitinami foi escolhido por ser uma abstraÃ§Ã£o para o Airflow. 
Fiz alguns testes com o operator oficial do airflow porÃ©m tive alguns problemas na configuraÃ§Ã£o do mesmo.

O airflow foi escolhido para ser o orquestrador dos jobs spark para criar uma escalabidade do deploy dos jobs. 
Nele Ã© utilizado a estratÃ©gia de clonar o repositÃ³rio que contÃ©m a definiÃ§Ã£o das Dag's.

Importante salientar que para o airflow utilizar o spark-operator e criar os jobs no namespace spark-job, foi necessÃ¡rio criar uma **Role** com a acesso ao grupo de api *sparkoperator.k8s.io* e uma **RoleBinding** para linkar a role e a **ServiceAccount** do *airflow-operator*. 
[airflow-rbac.yml](airflow-operator/airflow-rbac.yml)

### Local setup

#### Variaveis de ambiente

No arquivo [.env.project](.env.project) tem as variveis de ambiente utilizadas neste projeto. 
Na estrutura do arquivo, temos algumas variaveis comentadas (#), estas variaveis sÃ£o sensiveis, e Ã© interessante que apenas que elas nÃ£o sejam versionadas e sim disponibilizadas por um vault.

Devido este projeto ser privado, Ã© necessÃ¡rio definirmos uma variavel chamada **SOURCE_PERSONAL_ACCESS_TOKEN**, que Ã© o token de acesso ao github (pode ser gerado em [github.com/settings/tokens](https://github.com/settings/tokens)) para o airflow poder clonar as DAG's definidas no folder [airflow-operator/dags](airflow-operator/dags).

#### Executando Local setup

```sh
sudo apt-get update && \
sudo apt-get install make -y
make setup
```

<details><summary>Show complete make setup</summary>
<p>

```sh
$ make setup
STEP: setup-local-install-binaries - Install kind k8s and binaries utilitys
Install kind in version v0.10.0
Install Kubectl in version v1.20.5
Install Helm in version 3
Helm v3.5.3 is already latest
Install mc-client
Setup finish
Setup finish
STEP: setup-local-init-kind - Initiate cluster kind
Creating cluster "data-challenge-stone" ...
 â€¢ Ensuring node image (kindest/node:v1.20.2) ğŸ–¼  ...
 âœ“ Ensuring node image (kindest/node:v1.20.2) ğŸ–¼
 â€¢ Preparing nodes ğŸ“¦ ğŸ“¦ ğŸ“¦ ğŸ“¦ ğŸ“¦ ğŸ“¦   ...
 âœ“ Preparing nodes ğŸ“¦ ğŸ“¦ ğŸ“¦ ğŸ“¦ ğŸ“¦ ğŸ“¦ 
 â€¢ Configuring the external load balancer âš–ï¸  ...
 âœ“ Configuring the external load balancer âš–ï¸
 â€¢ Writing configuration ğŸ“œ  ...
 âœ“ Writing configuration ğŸ“œ
 â€¢ Starting control-plane ğŸ•¹ï¸  ...
 âœ“ Starting control-plane ğŸ•¹ï¸
 â€¢ Installing CNI ğŸ”Œ  ...
 âœ“ Installing CNI ğŸ”Œ
 â€¢ Installing StorageClass ğŸ’¾  ...
 âœ“ Installing StorageClass ğŸ’¾
 â€¢ Joining more control-plane nodes ğŸ®  ...
 âœ“ Joining more control-plane nodes ğŸ®
 â€¢ Joining worker nodes ğŸšœ  ...
 âœ“ Joining worker nodes ğŸšœ
Set kubectl context to "kind-data-challenge-stone"
You can now use your cluster with:

kubectl cluster-info --context kind-data-challenge-stone

Thanks for using kind! ğŸ˜Š
STEP: setup-k8s-spark-operator - Install spark-operator
kubectl create namespaces for spark
namespace/spark-operator created
namespace/spark-job created
Helm add repository spark-operator
"spark-operator" already exists with the same configuration, skipping
Helm install spark-operator
W0405 00:28:12.144403  258372 warnings.go:70] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
W0405 00:28:12.476574  258372 warnings.go:70] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
W0405 00:28:14.685940  258372 warnings.go:70] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
W0405 00:28:17.211054  258372 warnings.go:70] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
W0405 00:28:17.398793  258372 warnings.go:70] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
NAME: spark
LAST DEPLOYED: Mon Apr  5 00:28:19 2021
NAMESPACE: spark-operator
STATUS: deployed
REVISION: 1
TEST SUITE: None
Setup finish
STEP: setup-auxiliaries-minio-operator - Install minio-operator
kubectl create namespaces for minio
namespace/minio-operator created
Helm add repository minio-operator
"bitnami" already exists with the same configuration, skipping
Helm install minio-operator
NAME: minio
LAST DEPLOYED: Mon Apr  5 00:28:38 2021
NAMESPACE: minio-operator
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
** Please be patient while the chart is being deployed **

MinIO(R) can be accessed via port 9000 on the following DNS name from within your cluster:

   minio.minio-operator.svc.cluster.local

To get your credentials run:

   export ACCESS_KEY=$(kubectl get secret --namespace minio-operator minio -o jsonpath="{.data.access-key}" | base64 --decode)
   export SECRET_KEY=$(kubectl get secret --namespace minio-operator minio -o jsonpath="{.data.secret-key}" | base64 --decode)

To connect to your MinIO(R) server using a client:

- Run a MinIO(R) Client pod and append the desired command (e.g. 'admin info'):

   kubectl run --namespace minio-operator minio-client \
     --rm --tty -i --restart='Never' \
     --env MINIO_SERVER_ACCESS_KEY=$ACCESS_KEY \
     --env MINIO_SERVER_SECRET_KEY=$SECRET_KEY \
     --env MINIO_SERVER_HOST=minio \
     --image docker.io/bitnami/minio-client:2021.3.23-debian-10-r3 -- admin info minio

To access the MinIO(R) web UI:

- Get the MinIO(R) URL:

   echo "MinIO(R) web URL: http://127.0.0.1:9000/minio"
   kubectl port-forward --namespace minio-operator svc/minio 9000:9000
Added `minio-local` successfully.
Setup finish
STEP: setup-k8s-airflow-operator - Install minio-operator
kubectl create namespaces for airflow
namespace/airflow-operator created
Helm add repository airflow-operator
"bitnami" already exists with the same configuration, skipping
Helm install airflow-operator
NAME: airflow
LAST DEPLOYED: Mon Apr  5 00:28:47 2021
NAMESPACE: airflow-operator
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
1. Get the Airflow URL by running:

  echo URL  : http://127.0.0.1:8080
  kubectl port-forward --namespace airflow-operator svc/airflow 8080:8080

2. Get your Airflow login credentials by running:
  export AIRFLOW_PASSWORD=$(kubectl get secret --namespace "airflow-operator" airflow -o jsonpath="{.data.airflow-password}" | base64 --decode)
  echo User:     MY_AIRFLOW_USERNAME
  echo Password: $AIRFLOW_PASSWORD
kubectl create rolebinding for use spark
role.rbac.authorization.k8s.io/airflow-sparkapplication created
rolebinding.rbac.authorization.k8s.io/airflow-sparkapplication created
Setup finish
```
</p>
</details>

### Cleanup environment

```sh
$ make clean
STEP: setup-local-cleanup - Destroy cluster kind
Deleting cluster "data-challenge-stone" ...
```

## ExecuÃ§Ã£o dos jobs

### Pyspark-Operator

ApÃ³s subir o ambiente (com a instalaÃ§Ã£o via kind, o conexto jÃ¡ Ã© setado) e tendo acesso ao cluster, podemos acessar a soluÃ§Ã£o.

```sh
vscode âœ /workspaces/data-challenge-stone (main âœ—) $ kubectl get nodes
NAME                                  STATUS   ROLES                  AGE   VERSION
data-challenge-stone-control-plane    Ready    control-plane,master   18m   v1.20.2
data-challenge-stone-control-plane2   Ready    control-plane,master   18m   v1.20.2
data-challenge-stone-control-plane3   Ready    control-plane,master   17m   v1.20.2
data-challenge-stone-worker           Ready    <none>                 17m   v1.20.2
data-challenge-stone-worker2          Ready    <none>                 17m   v1.20.2
data-challenge-stone-worker3          Ready    <none>                 17m   v1.20.2
vscode âœ /workspaces/data-challenge-stone (main âœ—) $ kubectl config get-contexts 
CURRENT   NAME                        CLUSTER                     AUTHINFO                    NAMESPACE
*         kind-data-challenge-stone   kind-data-challenge-stone   kind-data-challenge-stone   
vscode âœ /workspaces/data-challenge-stone (main âœ—) $ 
```

No cluster, temos configurado todos os operators acima citados. 
Como um primeiro exemplo irei executar a applicaÃ§Ã£o **pagerank** via sparkOperator diretamente.

```sh
$ kubectl apply -f spark-applications/pagerank/pagerank.yml 
sparkapplication.sparkoperator.k8s.io/pyspark-pagerank created

$ kubectl get pods --namespace spark-job -w
NAME                      READY   STATUS              RESTARTS   AGE
pyspark-pagerank-driver   0/1     ContainerCreating   0          2m22s
pyspark-pagerank-driver   1/1     Running             0          2m23s
pythonpagerank-febf12789f23d742-exec-1   0/1     Pending             0          0s
pythonpagerank-febf12789f23d742-exec-2   0/1     Pending             0          0s
pythonpagerank-febf12789f23d742-exec-3   0/1     Pending             0          0s
pythonpagerank-febf12789f23d742-exec-1   0/1     ContainerCreating   0          8s
pythonpagerank-febf12789f23d742-exec-2   0/1     ContainerCreating   0          8s
pythonpagerank-febf12789f23d742-exec-3   0/1     ContainerCreating   0          8s
pythonpagerank-febf12789f23d742-exec-2   1/1     Running             0          11s
pyspark-pagerank-driver                  0/1     Completed           0          3m45s
pythonpagerank-febf12789f23d742-exec-2   0/1     Terminating         0          74s
pythonpagerank-febf12789f23d742-exec-2   0/1     Terminating         0          74s
pythonpagerank-febf12789f23d742-exec-2   0/1     Terminating         0          74s
```

Podemos obter os logs da execuÃ§Ã£o com: 
* `kubectl logs pyspark-pagerank-driver --namespace=spark-job`

e os detalhes macro da aplicaÃ§Ã£o com:

* `kubectl describe sparkapplications pyspark-pagerank --namespace=spark-job`

```sh
$ kubectl describe sparkapplications pyspark-pagerank --namespace=spark-job
Name:         pyspark-pagerank
Namespace:    spark-job
API Version:  sparkoperator.k8s.io/v1beta2
Kind:         SparkApplication
.
.
.
Events:
  Type    Reason                     Age                    From            Message
  ----    ------                     ----                   ----            -------
  Normal  SparkApplicationAdded      6m42s                  spark-operator  SparkApplication pyspark-pagerank was added, enqueuing it for submission
  Normal  SparkApplicationSubmitted  6m39s                  spark-operator  SparkApplication pyspark-pagerank was submitted successfully
  Normal  SparkDriverRunning         4m13s                  spark-operator  Driver pyspark-pagerank-driver is running
  Normal  SparkExecutorPending       4m8s                   spark-operator  Executor pythonpagerank-febf12789f23d742-exec-1 is pending
  Normal  SparkExecutorPending       4m8s                   spark-operator  Executor pythonpagerank-febf12789f23d742-exec-2 is pending
  Normal  SparkExecutorPending       4m7s                   spark-operator  Executor pythonpagerank-febf12789f23d742-exec-3 is pending
  Normal  SparkExecutorRunning       3m57s                  spark-operator  Executor pythonpagerank-febf12789f23d742-exec-2 is running
  Normal  SparkDriverCompleted       2m54s (x2 over 2m54s)  spark-operator  Driver pyspark-pagerank-driver completed
  Normal  SparkExecutorCompleted     2m54s                  spark-operator  Executor pythonpagerank-febf12789f23d742-exec-2 completed
  Normal  SparkApplicationCompleted  2m54s                  spark-operator  SparkApplication pyspark-pagerank completed
```

### Airflow-Operator

O operador do airflow estÃ¡ em execuÃ§Ã£o, porÃ©m para acessar Ã© necessÃ¡rio fazer um port-foward do cluster para a maquina. 
Caso nÃ£o queira realizar o procedimento, pode-se criar um service com um escopo do tipo nodePort.

```sh
$ kubectl get all --namespace=airflow-operator
NAME                                     READY   STATUS    RESTARTS   AGE
pod/airflow-postgresql-0                 1/1     Running   0          37m
pod/airflow-redis-master-0               1/1     Running   0          37m
pod/airflow-scheduler-85bb89fb95-6778f   2/2     Running   0          37m
pod/airflow-web-7c84564f55-kqbpp         2/2     Running   0          37m
pod/airflow-worker-0                     2/2     Running   0          37m

NAME                                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
service/airflow                       ClusterIP   10.96.8.8       <none>        8080/TCP   37m
service/airflow-postgresql            ClusterIP   10.96.158.13    <none>        5432/TCP   37m
service/airflow-postgresql-headless   ClusterIP   None            <none>        5432/TCP   37m
service/airflow-redis-headless        ClusterIP   None            <none>        6379/TCP   37m
service/airflow-redis-master          ClusterIP   10.96.187.130   <none>        6379/TCP   37m
service/airflow-worker-headless       ClusterIP   None            <none>        8793/TCP   37m

NAME                                READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/airflow-scheduler   1/1     1            1           37m
deployment.apps/airflow-web         1/1     1            1           37m

NAME                                           DESIRED   CURRENT   READY   AGE
replicaset.apps/airflow-scheduler-85bb89fb95   1         1         1       37m
replicaset.apps/airflow-web-7c84564f55         1         1         1       37m

NAME                                    READY   AGE
statefulset.apps/airflow-postgresql     1/1     37m
statefulset.apps/airflow-redis-master   1/1     37m
statefulset.apps/airflow-worker         1/1     37m
```

#### Acessando a console do airflow

O usuÃ¡rio e senha de acesso a console do Airflow sÃ£o definidos nas variaveis *AIRFLOW_USERNAME* e *AIRFLOW_PASSWORD*

```sh
make k8s-port-foward-airflow
STEP: k8s-port-foward-airflow - Port Foward to access airflow console
Airflow web URL: http://127.0.0.1:8080
Forwarding from 127.0.0.1:8080 -> 8080
```

![airflow-login](img/airflow-login.png)

ApÃ³s o login Ã© possivel vizualizar as Dags definidas no projeto

![dags](img/dags.png)

Ã‰ necessÃ¡rio fazer um ajuste na configuraÃ§Ã£o da conexÃ£o com o kubernetes do airflow. 
Este ajuste Ã© necessÃ¡rio devido a configuraÃ§Ã£o customizada da connection nÃ£o ter sido feita em um ConfigMap customizado ou na decalaraÃ§Ã£o do helm.

```txt
Admin -> Connections -> edit kubernetes_default -> check In cluster configuration -> save
```

![connection-configuration](img/connection-configuration.png)

Essa configuraÃ§Ã£o Ã© necessÃ¡ria para que o airflow identifique que a conexÃ£o com o kubernetes que ele irÃ¡ utilizar serÃ¡ local. 
Caso nÃ£o executado recebemos o seguinte erro:

```txt
{taskinstance.py:1455} ERROR - Invalid kube-config file. No configuration found.
```

#### Executando o Workflow

Podemos acessar a dag e ver o seu workflow. [http://127.0.0.1:8080/graph?dag_id=spark_pagerank](http://127.0.0.1:8080/graph?dag_id=spark_pagerank)

![dag_spark_pagerank](img/dag_spark_pagerank.png)

Podemos triggar ela e apÃ³s a execuÃ§Ã£o do step ver o log que foi gerado.

![dag_trigged](img/dag_trigged.png)

![dag_access_to_log](img/dag_access_to_log.png)

![airflow-log-spark](img/airflow-log-spark.png)

## Deployando a soluÃ§Ã£o em um ambiente com o cluster jÃ¡ disponivel

### Passo 0 - configurar as variaveis de ambiente

Pode ser utilizado os arquivos `.env.private` e `.env.project`, ou as variaveis podem ser injetas por outra estratÃ©gia.
Mas sÃ£o necessÃ¡rias:

```sh
MINIO_ACCESS_KEY=MY_MINIO_ACCESS_KEY
MINIO_SECRET_KEY=MY_MINIO_SECRET_KEY

AIRFLOW_USERNAME=MY_AIRFLOW_USERNAME
AIRFLOW_PASSWORD=MY_AIRFLOW_PASSWORD

# Para o airflow acessar clonar o repositÃ³rio com as dags
SOURCE_USERNAME=                  # afonsoaugusto
SOURCE_PERSONAL_ACCESS_TOKEN=     # token gerado
SOURCE_REPOSITORY=                # data-challenge-stone
SOURCE_REPO_IDENTIFIER=           # data-challenge-stone
SOURCE_BRANCH=                    # main
SOURCE_BRAND=                     # github.com
```

### Passo 1 - configurar o acesso ao cluster

Ã‰ necessÃ¡rio que ambiente que esteja executando, tenha acesso ao cluster. 
Os utilitÃ¡rios podem ser ser instalados atraves do comando `make setup-local-install-binaries`

### Passo 2 - instalar os operadores no cluster

Cada operador Ã© opcional na sua instalaÃ§Ã£o caso jÃ¡ tenha instalado.

* Spark: `make setup-k8s-spark-operator`
* Minio:  `make setup-auxiliaries-minio-operator`
* Airflow: `make setup-k8s-airflow-operator`

### Passo 3 - EvoluÃ§Ã£o das aplicaÃ§Ãµes

A aplicaÃ§Ãµes sÃ£o definidas em dois pontos:

* spark-applications -> onde Ã© aplicaÃ§Ã£o spark e a criaÃ§Ã£o da sua imagem
* airflow-operator/dags -> onde Ã© o workflow da mesma

```sh
â”œâ”€â”€ airflow-operator               ----- Para DeclaraÃ§Ã£o da Dag no Airflow -----
â”‚   â””â”€â”€ dags
â”‚       â”œâ”€â”€ spark-pagerank.yml
â”‚       â”œâ”€â”€ spark_pagerank.py
â”œâ”€â”€ spark-applications            ----- Para criar a imagem base e pode executar um SparkApplication diretamente -----
â”‚   â””â”€â”€ pagerank
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ pagerank.py
```

Portanto, para continuar na adiÃ§Ã£o de novas aplicaÃ§Ãµes ou jobs Ã© necessÃ¡rio:

* Criar um diretÃ³rio para aplicaÃ§Ã£o spark em spark-applications contendo
  * Dockerfile
  * source_code
* Criar uma dag definition e um spark definition no diretÃ³rio airflow-operator/dags

## Mono-repo ou Multi-repo

Como o objetivo do challenge Ã© uma proposta de soluÃ§Ã£o entÃ£o o mesmo foi desenvolvido em um unico repositÃ³rio.
PorÃ©m inicialmente para evoluÃ§Ã£o do projeto eu sugiro a divisÃ£o deste repositÃ³rio em 3 projetos.

1. Um respositÃ³rio para conter os scripts e a automaÃ§Ã£o da criaÃ§Ã£o do cluster
2. Um respositÃ³rio para conter a automaÃ§Ã£o da aplicaÃ§Ã£o da estrutura dos operators e sua configuraÃ§Ã£o
3. Um respositÃ³rio para conter as AplicaÃ§Ãµes onde consiste na definiÃ§Ã£o das Dags e do SparkApplication (application.language, libs, Dockerfile).

## TODO

* Automatizar a criaÃ§Ã£o de connections do airflow
* Melhorar as configuraÃ§Ãµes do airflow e/ou mudar o chart utilizado para cria-lo.
* Utilizar o minio disponibilizado no projeto
* Criar mais aplicaÃ§Ãµes de exemplo
* Desenhar de forma mais detalhada a arquitetura do projeto
* Melhorar o build das imagens respeitando a branch onde estÃ¡ sendo executada, assim podendo ser referenciada mais especificamente na definiÃ§Ã£o da AplicaÃ§Ã£o e ser testada em um ambiente de desenvolvimento/homologaÃ§Ã£o
* Modificar estratÃ©gia de passagem de valores para a definiÃ§Ã£o da aplicaÃ§Ã£o spark, sendo possivel customizar o nome da imagem a ser executado

## ReferÃªncias

* [kubectl/cheatsheet](https://kubernetes.io/pt/docs/reference/kubectl/cheatsheet/)
* [Kind](https://kind.sigs.k8s.io/)
* [Helm](https://helm.sh/docs/)
* [spark-on-k8s-operator](https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/)
* [Minio-operator](https://github.com/minio/operator/blob/master/README.md)
* [Airflow-operator](https://github.com/bitnami/charts/tree/master/bitnami/airflow)
